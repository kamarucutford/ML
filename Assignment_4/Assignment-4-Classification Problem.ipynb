{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3a997c-15a4-49ed-8102-b659d9640262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.drop('target', axis=1))\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df.columns[:-1])\n",
    "df_scaled['target'] = df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled.drop('target', axis=1), df_scaled['target'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0699454-cd01-4928-bd40-d43971fa808c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Explanation:\n",
    "\n",
    "Missing values: Check for missing values in the dataset and handle them (if any) by imputing or removing them. In this case, the dataset does not have missing values.\n",
    "\n",
    "Feature scaling: Standardize the features to have a mean of 0 and a standard deviation of 1, which is crucial for algorithms like SVM and k-NN that are sensitive to feature scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b808e6-03bc-4145-b26e-a5f407b5b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# 1. Logical Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_score = lr.score(X_test, y_test)\n",
    "print(f\"Logistic Regression Accuracy: {lr_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff37b8f-6899-414c-a329-272d480d446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_score = dt.score(X_test, y_test)\n",
    "print(f\"Decision Tree Accuracy: {dt_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3600afd7-589d-4a0f-84f2-25f849c52705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# 3. Randon Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "print(f\"Random Forest Accuracy: {rf_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d12d611-1e34-4e02-b17f-0da8172a68f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# 4.Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_score = svm.score(X_test, y_test)\n",
    "print(f\"SVM Accuracy: {svm_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a9d124-8cc2-446a-9649-d9ac5c46db25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# 5. k-nearest Neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(f\"k-NN Accuracy: {knn_score:.2f}\")\n",
    "\n",
    "# Description: k-NN classifies a sample based on the majority class of its k nearest neighbors. It's simple but can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a1ebc83-cc3b-4d23-9675-1c5722d689bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Logistic Regression with Accuracy: 0.97\n",
      "Worst Model: Decision Tree with Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"Logistic Regression\": lr_score,\n",
    "    \"Decision Tree\": dt_score,\n",
    "    \"Random Forest\": rf_score,\n",
    "    \"SVM\": svm_score,\n",
    "    \"k-NN\": knn_score\n",
    "}\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "worst_model = min(results, key=results.get)\n",
    "\n",
    "print(f\"Best Model: {best_model} with Accuracy: {results[best_model]:.2f}\")\n",
    "print(f\"Worst Model: {worst_model} with Accuracy: {results[worst_model]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd77d9-d2d0-4115-b1be-c97c4179762a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
